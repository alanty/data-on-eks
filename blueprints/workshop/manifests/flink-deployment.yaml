apiVersion: flink.apache.org/v1beta1
kind: FlinkDeployment
metadata:
  name: cat-cafe-raw-ingestion
  namespace: flink-team-a
spec:
  image: public.ecr.aws/m8u6z8z4/manabu-test:flink-2.0-py-3-11@sha256:a535c8893d6dfaddcfee6646f516d1b1dd2e94adc7f3ba74152a22aabef5dc0d
  flinkVersion: v2_0
  serviceAccount: flink-team-a
  
  jobManager:
    resource:
      memory: "2048m"
      cpu: 1
    replicas: 1
  
  taskManager:
    resource:
      memory: "2048m"
      cpu: 1
    replicas: 2
  
  job:
    jarURI: local:///opt/flink/opt/flink-python-2.1.0.jar
    entryClass: org.apache.flink.client.python.PythonDriver
    args:
      - "-py"
      - "/tmp/raw-ingestion.py"
      # - "s3://data-on-eks-spark-logs-20250915164903963600000002/flink-jobs/raw-ingestion.py"
      # - "--pyRequirements"
      # - "s3a://data-on-eks-spark-logs-20250915164903963600000002/flink-jobs/flink-requirements.txt"
      # - "--pyArchives"
      # - "s3a://data-on-eks-spark-logs-20250915164903963600000002/flink-jobs/python-modules.zip"
    parallelism: 2
    upgradeMode: stateless
  
  flinkConfiguration:
    # logger.root.level: DEBUG
    # logger.org.apache.flink.client.python: DEBUG
    # logger.org.apache.flink.python: DEBUG
    # # Fix logging conflicts
    # rootLogger.level: INFO
    # rootLogger.appenderRef.console.ref: ConsoleAppender
    # appender.console.name: ConsoleAppender
    # appender.console.type: CONSOLE
    # appender.console.layout.type: PatternLayout
    # appender.console.layout.pattern: "%d{yyyy-MM-dd HH:mm:ss,SSS} %-5p %-60c %x - %m%n"
    taskmanager.numberOfTaskSlots: "2"
    state.checkpoints.dir: s3a://data-on-eks-spark-logs-20250915164903963600000002/flink-checkpoints/
    execution.checkpointing.interval: 120s
    execution.checkpointing.mode: EXACTLY_ONCE
    
    # S3 Configuration
    s3.endpoint: https://s3.amazonaws.com
    s3.path.style.access: false
    
    # Iceberg Configuration
    table.exec.iceberg.write.metadata.delete-after-commit.enabled: "true"
    table.exec.iceberg.write.metadata.previous-versions-max: "5"
    
    env.java.opts.jobmanager: "-DKAFKA_BOOTSTRAP_SERVERS=cluster-broker-0.cluster-kafka-brokers.kafka.svc:9092"
    env.java.opts.taskmanager: "-DKAFKA_BOOTSTRAP_SERVERS=cluster-broker-0.cluster-kafka-brokers.kafka.svc:9092"

    # datahub configuration
    execution.job-status-changed-listeners: "io.openlineage.flink.listener.OpenLineageJobStatusChangedListenerFactory"
    openlineage.transport.type: "http"
    openlineage.transport.url: "http://data-on-eks-datahub-gms.datahub.svc.cluster.local:8080/openapi/openlineage/api/v1/lineage"
    openlineage.transport.auth.type: api_key
    openlineage.transport.auth.apiKey: "$DATAHUB_TOKEN"
    openlineage.job.namespace: "workshop"
    openlineage.job.name: "cat-cafe-raw-ingestion"

  
  podTemplate:
    metadata:
      annotations:
        kubectl.kubernetes.io/restartedAt: "RESTART_TIMESTAMP"
    spec:
      volumes:
        - name: python-script
          configMap:
            name: raw-ingestion-py
      containers:
        - name: flink-main-container
          volumeMounts:
            - name: python-script
              mountPath: /tmp/raw-ingestion.py
              subPath: raw-ingestion.py
          # args:
          #   - "bash"
          #   - "-c"
          #   - "sleep 3600"
          env:
            - name: KAFKA_BOOTSTRAP_SERVERS
              value: "cluster-broker-0.cluster-kafka-brokers.kafka.svc:9092"
            - name: S3_WAREHOUSE_PATH
              value: "s3a://data-on-eks-spark-logs-20250915164903963600000002/iceberg-warehouse/"
            - name: AWS_REGION
              value: "us-west-2"
            - name: AWS_JAVA_V1_DISABLE_DEPRECATION_ANNOUNCEMENT
              value: "true"
            - name: WORKSHOP_DEBUG
              value: "false"
            - name: DATAHUB_TOKEN
              valueFrom:
                secretKeyRef:
                  name: datahub-token
                  key: token
            # - name: ENABLE_BUILT_IN_PLUGINS
            #   value: "flink-s3-fs-hadoop-2.0.0.jar"
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: raw-ingestion-py
  namespace: flink-team-a
data:
  raw-ingestion.py: |
    PYTHON_SCRIPT_CONTENT
---
apiVersion: v1
kind: Secret
metadata:
  name: datahub-token
  namespace: flink-team-a
type: Opaque
stringData:
  token: $DATAHUB_TOKEN
