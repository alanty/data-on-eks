{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf05030c-f6a6-464a-ae42-52d4d8f5013b",
   "metadata": {},
   "source": [
    "# Using Iceberg and Query Engines\n",
    "\n",
    "This notebook demonstrates how you can use Iceberg and Spark / Trino to query your data.\n",
    "\n",
    "We will:\n",
    "- Configure Spark with Iceberg runtime libaries\n",
    "- Explore how iceberg works\n",
    "- Explore data we just generated\n",
    "- Come up with a plan to run a Spark job with Spark Operator\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3175d793-7264-4e15-9797-0c39ca654554",
   "metadata": {},
   "source": [
    "## Setting up Spark and Iceberg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2d11268-89cb-4b55-9fd5-cf200872669d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import os\n",
    "\n",
    "# These packages are necessary for running this section on EKS. We have made these jars available within the container image, therefore the line below is commented out.\n",
    "# packages = \"org.apache.iceberg:iceberg-spark:1.10.0,org.apache.iceberg:iceberg-spark-runtime-4.0_2.13:1.10.0,org.apache.iceberg:iceberg-spark-extensions-4.0_2.13:1.10.0,com.amazonaws:aws-java-sdk-bundle:1.12.791,software.amazon.awssdk:bundle:2.34.0,org.apache.hadoop:hadoop-aws:3.4.1\"\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"IcebergInspector\") \\\n",
    "    .config(\"spark.sql.catalog.workshop\", \"org.apache.iceberg.spark.SparkCatalog\") \\\n",
    "    .config(\"spark.sql.catalog.workshop.type\", \"glue\") \\\n",
    "    .config(\"spark.sql.extensions\", \"org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions\") \\\n",
    "    .config(\"spark.sql.defaultCatalog\", \"workshop\") \\\n",
    "    .config(\"spark.sql.catalog.workshop.warehouse\", \"s3a://data-on-eks-spark-logs-20251001184655839600000005/iceberg-warehouse/\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\").getOrCreate()\n",
    "    # .config(\"spark.sql.catalog.workshop.io-impl\", \"org.apache.iceberg.aws.s3.S3FileIO\") \\\n",
    "\n",
    "\n",
    "spark.sparkContext.setLogLevel(\"DEBUG\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec19e0d-7e36-471a-a382-c412f002cb2c",
   "metadata": {},
   "source": [
    "## Explore Iceberg Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c8ebc36-9834-4046-8831-e647f846ff6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|  namespace|\n",
      "+-----------+\n",
      "|data_on_eks|\n",
      "+-----------+\n",
      "\n",
      "+-----------+--------------------+-----------+\n",
      "|  namespace|           tableName|isTemporary|\n",
      "+-----------+--------------------+-----------+\n",
      "|data_on_eks|     cafe_orders_raw|      false|\n",
      "|data_on_eks|cafe_orders_raw_6...|      false|\n",
      "|data_on_eks|cat_interactions_raw|      false|\n",
      "|data_on_eks|cat_interactions_...|      false|\n",
      "|data_on_eks|   cat_locations_raw|      false|\n",
      "|data_on_eks|cat_locations_raw...|      false|\n",
      "|data_on_eks|    cat_wellness_raw|      false|\n",
      "|data_on_eks|cat_wellness_raw_...|      false|\n",
      "|data_on_eks|visitor_checkins_raw|      false|\n",
      "|data_on_eks|visitor_checkins_...|      false|\n",
      "+-----------+--------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# We read database information from the catalog\n",
    "spark.sql(\"show databases\").show()\n",
    "# Then use the database for all queries going forward.\n",
    "spark.sql(\"use data_on_eks\")\n",
    "# Show all tables available with in the database\n",
    "spark.sql(\"show tables\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23cd614b-83eb-400c-9a40-57a944a74f3c",
   "metadata": {},
   "source": [
    "# Peeking Under the Hood: Exploring Metadata Tables\n",
    "One of Iceberg's most powerful features is its transparency. Unlike other table formats where the underlying structure is hidden, Iceberg allows us to directly query its metadata to understand exactly what's going on.\n",
    "We'll use special sub-tables like .files, .history, and .snapshots to inspect the table's physical layout and history.\n",
    "\n",
    "Let's start by looking at the actual data files on disk. Every time we write data, Iceberg creates one or more files (in this case, Parquet files). The .files metadata table gives us a complete list of every data file that makes up the current snapshot of the table.\n",
    "This demonstrates how small, frequent writes can lead to multiple small files.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16193234-adb3-4ac0-b4d4-f2bba988eafc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------+------------------+------------+\n",
      "|           file_path|file_format|file_size_in_bytes|record_count|\n",
      "+--------------------+-----------+------------------+------------+\n",
      "|s3a://data-on-eks...|    PARQUET|             98651|       23820|\n",
      "|s3a://data-on-eks...|    PARQUET|             99303|       24007|\n",
      "|s3a://data-on-eks...|    PARQUET|             98269|       23767|\n",
      "|s3a://data-on-eks...|    PARQUET|             99176|       23930|\n",
      "|s3a://data-on-eks...|    PARQUET|             98700|       23827|\n",
      "|s3a://data-on-eks...|    PARQUET|             40429|        6132|\n",
      "|s3a://data-on-eks...|    PARQUET|             89337|       21136|\n",
      "+--------------------+-----------+------------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT\n",
    "    file_path, file_format, file_size_in_bytes, record_count\n",
    "FROM\n",
    "    spark_catalog.data_on_eks.cat_locations_raw.files\n",
    "ORDER BY file_path DESC\n",
    "LIMIT 10\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c3fc74-a0e7-4747-abbc-e65a2060b85b",
   "metadata": {},
   "source": [
    "## The History Table\n",
    "The .history table is like a commit log for your data. Every change made to the table—like our INSERT statements—is recorded as an entry. This provides a clear, chronological audit trail of how the table has evolved. The query below will show the timeline of when each snapshot became the current version of the table. C. Show the Snapshot Details (.snapshots) While .history shows the timeline, the .snapshots table gives us the rich details for each snapshot. A snapshot is an immutable view of the table's complete state at a specific point in time. The query below shows what operation created each snapshot (append, overwrite, etc.) and a summary of the changes, like how many records and files were added. This table is the key that enables powerful features like time travel.\n",
    "\n",
    "The `is_current_ancestor` column is a boolean flag in the history table that answers a simple question: \"Is this historical snapshot part of the direct timeline that leads to the table's current state?\"\n",
    "\n",
    "  * If the value is **`true`**, the snapshot is a direct ancestor.\n",
    "  * If the value is **`false`**, the snapshot belongs to an abandoned branch of history, most often created after a table rollback.\n",
    "\n",
    "The diagrams below illustrate how this works.\n",
    "\n",
    "-----\n",
    "\n",
    "### Scenario 1: Linear History\n",
    "\n",
    "Initially, your table has three commits (snapshots). Each is a direct ancestor of the current version (`S3`), so `is_current_ancestor` is **true** for all of them.\n",
    "\n",
    "```\n",
    "(Main Timeline)\n",
    "+-------------+      +-------------+      +-------------+\n",
    "| Snapshot S1 |----->| Snapshot S2 |----->| Snapshot S3 |\n",
    "| ancestor: T |      | ancestor: T |      | ancestor: T |\n",
    "+-------------+      +-------------+      +-------------+\n",
    "                                                    ^\n",
    "                                                    |\n",
    "                                                 (current)\n",
    "```\n",
    "\n",
    "\n",
    "### Scenario 2: After Rolling Back to S2\n",
    "\n",
    "Now, you roll the table back to `S2`. The main timeline is now shorter, and `S2` is the new current version.\n",
    "\n",
    "Snapshot `S3` still exists in the table's history, but it's now on an **abandoned branch**. Its `is_current_ancestor` flag flips to **false**.\n",
    "\n",
    "```\n",
    "(Main Timeline)                               (Abandoned Branch)\n",
    "+-------------+      +-------------+                 +-------------+\n",
    "| Snapshot S1 |----->| Snapshot S2 |                 | Snapshot S3 |\n",
    "| ancestor: T |      | ancestor: T |                 | ancestor: F |\n",
    "+-------------+      +-------------+                 +-------------+\n",
    "                           ^\n",
    "                           |\n",
    "                        (current)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "35285816-a143-4c0f-9807-63f8d218b9a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-------------------+-------------------+\n",
      "|     made_current_at|        snapshot_id|          parent_id|is_current_ancestor|\n",
      "+--------------------+-------------------+-------------------+-------------------+\n",
      "|2025-10-02 18:16:...| 686702856221647031|               NULL|               true|\n",
      "|2025-10-02 18:18:...|6250352781994368215| 686702856221647031|               true|\n",
      "|2025-10-02 18:20:...|7910074619865715724|6250352781994368215|               true|\n",
      "|2025-10-02 18:22:...| 705454000691502411|7910074619865715724|               true|\n",
      "|2025-10-02 18:24:...|4643221966159991104| 705454000691502411|               true|\n",
      "|2025-10-02 18:26:...|2900310610060766013|4643221966159991104|               true|\n",
      "|2025-10-02 18:28:...| 245501116594841622|2900310610060766013|               true|\n",
      "|2025-10-02 18:30:...| 656001455602482726| 245501116594841622|               true|\n",
      "|2025-10-02 18:32:...|2576547903821103422| 656001455602482726|               true|\n",
      "|2025-10-02 18:34:...|6025447762788055104|2576547903821103422|               true|\n",
      "|2025-10-02 18:36:...|7136945472435341618|6025447762788055104|               true|\n",
      "|2025-10-02 18:38:...|1480665027121453578|7136945472435341618|               true|\n",
      "|2025-10-02 18:40:...|4737516467032851775|1480665027121453578|               true|\n",
      "|2025-10-02 18:53:...|4044823615142359893|4737516467032851775|               true|\n",
      "|2025-10-02 18:55:...|6061912960086116628|4044823615142359893|               true|\n",
      "+--------------------+-------------------+-------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT\n",
    "    *\n",
    "FROM\n",
    "    workshop.data_on_eks.cat_locations_raw.history\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "989dd70d-d346-4b3e-8c21-e4940b3af006",
   "metadata": {},
   "source": [
    "#### Now that we understand how to view the metadata, let's use it to demonstrate some of Iceberg's most famous features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "076c97b0-ae17-4fec-b7e7-d0f878b54b20",
   "metadata": {},
   "source": [
    "## Schema Evolution (The \"No-Panic\" Schema Change)\n",
    "\n",
    "This is one of Iceberg's most valuable features. It allows you to change a table's schema without rewriting all the existing data.\n",
    "\n",
    "  * **How to demonstrate:**\n",
    "    1.  **Show the current schema:**\n",
    "        ```sql\n",
    "        DESCRIBE TABLE workshop.`data-on-eks`.daily_cat_summary\n",
    "        ```\n",
    "    2.  **Add a new column:** Run an `ALTER TABLE` command. This is a metadata-only operation and will complete instantly.\n",
    "        ```sql\n",
    "        ALTER TABLE workshop.`data-on-eks`.daily_cat_summary ADD COLUMN notes STRING\n",
    "        ```\n",
    "    3.  **Verify the new schema:**\n",
    "        ```sql\n",
    "        DESCRIBE TABLE workshop.`data-on-eks`.daily_cat_summary\n",
    "        ```\n",
    "    4.  **Query the data:** Show that the table is still perfectly readable. Old rows will simply have a `null` value for the new `notes` column.\n",
    "        ```sql\n",
    "        SELECT day, cat_id, name, notes FROM workshop.`data-on-eks`.daily_cat_summary LIMIT 10\n",
    "        ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1b6ae4d1-3df8-4ecf-9f3a-9b1abb880245",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------+----------+----------------------+----------+\n",
      "|          event_time|              cat_id|activity_level|heart_rate|hours_since_last_drink|event_date|\n",
      "+--------------------+--------------------+--------------+----------+----------------------+----------+\n",
      "|2025-10-02T18:53:...|e288cb79-0721-49b...|          3.16|       102|                   3.6|2025-10-02|\n",
      "|2025-10-02T18:53:...|bee21146-e74b-4b3...|          8.54|       102|                  2.81|2025-10-02|\n",
      "|2025-10-02T18:53:...|95421121-7507-478...|          1.22|       111|                  3.34|2025-10-02|\n",
      "|2025-10-02T18:53:...|960795a9-01f6-4d5...|          7.92|        98|                  2.89|2025-10-02|\n",
      "|2025-10-02T18:53:...|147ed417-2cda-496...|          1.27|        88|                  2.97|2025-10-02|\n",
      "|2025-10-02T18:53:...|78d188ea-bc24-4ec...|          9.37|        87|                   2.2|2025-10-02|\n",
      "|2025-10-02T18:53:...|9438bd05-cc1f-4ad...|          3.76|       102|                  3.45|2025-10-02|\n",
      "|2025-10-02T18:53:...|ca61f801-a3c9-4c5...|          1.39|        94|                  2.63|2025-10-02|\n",
      "|2025-10-02T18:53:...|93c898fc-da1d-470...|          5.26|       119|                  3.47|2025-10-02|\n",
      "|2025-10-02T18:53:...|601472b7-a782-4b0...|           2.3|        99|                  1.14|2025-10-02|\n",
      "|2025-10-02T18:53:...|2402a287-bb79-4b8...|          5.26|        82|                  3.11|2025-10-02|\n",
      "|2025-10-02T18:53:...|5277c3ff-10b1-42e...|          7.61|       103|                  0.53|2025-10-02|\n",
      "|2025-10-02T18:53:...|79746920-3e5c-4fb...|           8.8|       118|                  1.46|2025-10-02|\n",
      "|2025-10-02T18:53:...|8db2b1c9-436d-41e...|          3.03|        97|                  1.69|2025-10-02|\n",
      "|2025-10-02T18:53:...|d57f5ea1-44fc-4e4...|          4.68|       109|                  2.12|2025-10-02|\n",
      "|2025-10-02T18:53:...|17b28757-657c-474...|          5.91|       109|                  0.93|2025-10-02|\n",
      "|2025-10-02T18:53:...|eb414239-0994-44e...|          5.36|        88|                  3.69|2025-10-02|\n",
      "|2025-10-02T18:53:...|1375e1c1-b215-415...|          8.27|       113|                  1.92|2025-10-02|\n",
      "|2025-10-02T18:53:...|9a9bbb7a-1050-450...|          9.51|       105|                  3.53|2025-10-02|\n",
      "|2025-10-02T18:53:...|d60739f7-ccc1-464...|          6.48|       113|                  0.85|2025-10-02|\n",
      "+--------------------+--------------------+--------------+----------+----------------------+----------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT\n",
    "    *\n",
    "FROM\n",
    "    workshop.data_on_eks.cat_wellness_raw\n",
    "WHERE\n",
    "    event_date is not NULL\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95ca7cab-94d5-462f-a1b8-9f18684e7729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------+----------------------------------------------------------------------------------------------------------------------+-------+\n",
      "|col_name                    |data_type                                                                                                             |comment|\n",
      "+----------------------------+----------------------------------------------------------------------------------------------------------------------+-------+\n",
      "|event_time                  |string                                                                                                                |NULL   |\n",
      "|cat_id                      |string                                                                                                                |NULL   |\n",
      "|activity_level              |double                                                                                                                |NULL   |\n",
      "|heart_rate                  |int                                                                                                                   |NULL   |\n",
      "|hours_since_last_drink      |double                                                                                                                |NULL   |\n",
      "|event_date                  |date                                                                                                                  |NULL   |\n",
      "|# Partition Information     |                                                                                                                      |       |\n",
      "|# col_name                  |data_type                                                                                                             |comment|\n",
      "|event_date                  |date                                                                                                                  |NULL   |\n",
      "|                            |                                                                                                                      |       |\n",
      "|# Metadata Columns          |                                                                                                                      |       |\n",
      "|_spec_id                    |int                                                                                                                   |       |\n",
      "|_partition                  |struct<event_date:date>                                                                                               |       |\n",
      "|_file                       |string                                                                                                                |       |\n",
      "|_pos                        |bigint                                                                                                                |       |\n",
      "|_deleted                    |boolean                                                                                                               |       |\n",
      "|                            |                                                                                                                      |       |\n",
      "|# Detailed Table Information|                                                                                                                      |       |\n",
      "|Name                        |workshop.data_on_eks.cat_wellness_raw                                                                                 |       |\n",
      "|Type                        |MANAGED                                                                                                               |       |\n",
      "|Location                    |s3a://data-on-eks-spark-logs-20251001184655839600000005/iceberg-warehouse/data_on_eks.db/cat_wellness_raw             |       |\n",
      "|Provider                    |iceberg                                                                                                               |       |\n",
      "|Table Properties            |[current-snapshot-id=3252097921687177083,format=iceberg/parquet,format-version=2,write.parquet.compression-codec=zstd]|       |\n",
      "|Statistics                  |132842496 bytes, 2075664 rows                                                                                         |NULL   |\n",
      "+----------------------------+----------------------------------------------------------------------------------------------------------------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "DESCRIBE TABLE EXTENDED workshop.data_on_eks.cat_wellness_raw\n",
    "\"\"\").show(100, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc3a77c-16e2-401d-b3c5-141061439c75",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
